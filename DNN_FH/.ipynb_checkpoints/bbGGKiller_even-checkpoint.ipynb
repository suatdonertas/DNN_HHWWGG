{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0123230",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8332eebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parameters of the training ###\n",
    "\n",
    "split = \"even\" \n",
    "#split = \"odd\" \n",
    "# split = even | odd -> on what split to train the model (will be in the name)\n",
    "# -> you need one \"odd\" and one \"even\" models to be put inside bamboo\n",
    "\n",
    "suffix = 'test'\n",
    "# Suffix that will be added to the saved model (so multiple DNNs can be trained)\n",
    "\n",
    "quantile = 0.95 # We will repeat the part of the weights rightmost tail\n",
    "# Eg : 0.95, means we take the 5% events on the right tail of training weight and repeat them\n",
    "# 1.0 means no correction (to be used if you want to diable it)\n",
    "\n",
    "# DNN hyperparameters #\n",
    "parameters = {\n",
    "    'epochs'                : 200,\n",
    "    'lr'                    : 0.001,\n",
    "    'batch_size'            : 256,\n",
    "    'n_layers'              : 3,\n",
    "    'n_neurons'             : 64,\n",
    "    'hidden_activation'     : 'relu',\n",
    "    'output_activation'     : 'sigmoid',\n",
    "    'l2'                    : 1e-6,\n",
    "    'dropout'               : 0.,\n",
    "    'batch_norm'            : True,\n",
    "}\n",
    "# L2 is an additional term in the loss function : l2 x ||W||**2 where ||W|| is the sum of all the DNN weights \n",
    "#    inside the neurons\n",
    "# -> when overfitting the weights take large values, this tells the optimizer the trade off between performances\n",
    "#    and generalization (from experience, a small value always helps)\n",
    "# Dropout is a frequency of killing neurons at each batch (no backprogation for them)\n",
    "# -> used generally when overfitting is detected, to avoid that the DNN learns too much \n",
    "#    (from experience, not always useful, put it when you see overfitting)\n",
    "# Batch normalization is a layer that normalizes the output of each neuron (see documentation)\n",
    "# -> usually helps that the gradient does not go too far and backprogation is always smooth (supposedly)\n",
    "#    (from experience : always used it, maybe not worth all the time)\n",
    "\n",
    "\n",
    "# Input variables\n",
    "input_vars=[\"Eta_ph1\",\n",
    "            \"Phi_ph1\",\n",
    "            #\"E_mGG_ph1\",\n",
    "            \"pT_mGG_ph1\",\n",
    "            \"Eta_ph2\",\n",
    "            \"Phi_ph2\",\n",
    "            #\"E_mGG_ph2\",\n",
    "            \"pT_mGG_ph2\",\n",
    "            \"deltaPhi_DiPh\",\n",
    "            \"deltaR_DiPh\",\n",
    "            \"nJets\",\n",
    "            \"E_jet1\",   \n",
    "            \"pT_jet1\",\n",
    "            \"Eta_jet1\",\n",
    "            \"Phi_jet1\", \n",
    "            \"E_jet2\",   \n",
    "            \"pT_jet2\",\n",
    "            \"Eta_jet2\",\n",
    "            \"Phi_jet2\",  \n",
    "            \"E_jet3\",   \n",
    "            \"pT_jet3\",\n",
    "            \"Eta_jet3\",\n",
    "            \"Phi_jet3\",\n",
    "            \"E_jet4\",   \n",
    "            \"pT_jet4\",\n",
    "            \"Eta_jet4\",\n",
    "            \"Phi_jet4\",\n",
    "            \"w1_pT\",\n",
    "            \"w1_eta\",\n",
    "            \"w1_mass\",\n",
    "            \"w2_pT\",\n",
    "            \"w2_eta\",\n",
    "            \"w2_mass\",\n",
    "            \"ww_pT\",\n",
    "            \"ww_eta\",\n",
    "            \"ww_mass\",\n",
    "            \"mindeltaRPJ\",\n",
    "            \"maxdeltaRPJ\",\n",
    "            \"deltaRJJ\",\n",
    "            \"deltaRJJ2\",\n",
    "            \"deltaPhi_HH\",\n",
    "            \"deltaR_HH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16348b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/scratch/fynu/sdonerta/ipykernel_4031325/1936232848.py:11: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  config = yaml.load(handle)\n"
     ]
    }
   ],
   "source": [
    "# Load the required data #\n",
    "outputPath = '/home/ucl/cp3/sdonerta/bamboodev/WWGG/DNNOpt_FH_Skim_04_02'\n",
    "skimFile = os.path.join(outputPath,'results','Skim_FH.parquet')\n",
    "yamlFile = os.path.join(outputPath,'plots.yml')\n",
    "\n",
    "# Load dataframe from parquet #\n",
    "df = pd.read_parquet(skimFile)\n",
    "\n",
    "# Load samples + plots data from yaml file #\n",
    "with open(yamlFile,'r') as handle:\n",
    "    config = yaml.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d30264b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut negative event weights #\n",
    "df = df[(df['weight']>0) & (df['weight']<300)]\n",
    "#df = df[df['weight']>0]\n",
    "\n",
    "# Cut events/samples #\n",
    "df = df[~df.process.str.contains(\"VBF\")]\n",
    "df = df[~df.process.str.contains(\"GluGluHToGG\")]\n",
    "df = df[~df.process.str.contains(\"ttH\")]\n",
    "df = df[~df.process.str.contains(\"VH\")]\n",
    "df = df[~df.process.str.contains(\"THQ\")]\n",
    "df = df[~df.process.str.contains(\"GluGluHToGG\")]\n",
    "df = df[~df.process.str.contains(\"W1\")]\n",
    "df = df[~df.process.str.contains(\"W2\")]\n",
    "df = df[~df.process.str.contains(\"W3\")]\n",
    "df = df[~df.process.str.contains(\"WGJJ\")]\n",
    "df = df[~df.process.str.contains(\"WGGJets\")]\n",
    "df = df[~df.process.str.contains(\"DY\")]\n",
    "df = df[~df.process.str.contains(\"ZG\")]\n",
    "df = df[~df.process.str.contains(\"WW\")]\n",
    "df = df[~df.process.str.contains(\"TT\")]\n",
    "df = df[~df.process.str.contains(\"TTW\")]\n",
    "\n",
    "df[\"label\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fecc7309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set labels #\n",
    "# df[\"label\"] = 0\n",
    "# for process in pd.unique(df['process']):\n",
    "#     if process not in config['files']:\n",
    "#         raise RuntimeError(f'Process {process} not found in yaml config file')\n",
    "#     if config['files'][process]['type'] == 'signal':\n",
    "#         df.loc[df['process']==process, ['label']] = 1\n",
    "\n",
    "df.loc[df.process.str.contains(\"GluGluToHHTo2B2G\"), ['label']] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12b641a7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       weight   Eta_ph1   Phi_ph1  pT_mGG_ph1   Eta_ph2   Phi_ph2  pT_mGG_ph2  \\\n",
      "0    0.000025  1.550125 -0.429081    1.146218 -0.046672  0.040071    0.259975   \n",
      "1    0.000025 -0.331597 -0.570010    1.414617  0.195925  0.322665    0.686229   \n",
      "2    0.000025 -0.010950 -2.823565    0.760772 -1.469144 -2.621348    0.511143   \n",
      "3    0.000025  1.161311  1.227916    0.606318 -0.432271 -0.724228    0.281025   \n",
      "4    0.000025  0.151180  2.670311    1.722849 -0.022241 -2.667792    0.675868   \n",
      "..        ...       ...       ...         ...       ...       ...         ...   \n",
      "4   54.671268 -2.392717 -0.644548    0.341475 -0.479692  2.095490    0.334221   \n",
      "5   54.671268 -2.027300  0.506560    0.344458  0.342403 -0.463093    0.300636   \n",
      "6   54.671268  1.474123 -0.947501    0.217085 -1.841440  2.814480    0.157748   \n",
      "7   54.671268 -0.314875  3.136145    0.740329 -1.333250  0.654747    0.286807   \n",
      "8   54.671268  0.828541 -2.872322    0.371863 -1.893330 -1.752634    0.186714   \n",
      "\n",
      "    deltaPhi_DiPh  deltaR_DiPh  nJets  ...    ww_eta      ww_mass  \\\n",
      "0        0.469152     1.664291      4  ...  3.194896   672.958923   \n",
      "1        0.892675     1.036893      4  ...  1.641236   946.791199   \n",
      "2        0.202216     1.472148      4  ...  0.229979   589.149414   \n",
      "3       -1.952143     2.519993      5  ...  2.304729   854.003601   \n",
      "4        0.945082     0.960862      4  ... -0.257412   387.911835   \n",
      "..            ...          ...    ...  ...       ...          ...   \n",
      "4        2.740039     3.341778      4  ...  0.482731  5248.701660   \n",
      "5       -0.969653     2.560414      4  ... -1.544019   558.982239   \n",
      "6       -2.521204     4.165264      4  ... -4.747016  2028.770142   \n",
      "7       -2.481398     2.682243      4  ...  0.243046   373.384308   \n",
      "8        1.119688     2.943176      4  ... -3.803882  2178.556885   \n",
      "\n",
      "    mindeltaRPJ  maxdeltaRPJ  deltaRJJ  deltaRJJ2  deltaPhi_HH  deltaR_HH  \\\n",
      "0      2.284928     3.012725  3.968900   3.113642    -3.040094   3.542051   \n",
      "1      0.983860     4.065130  3.455338   2.105960    -3.057976   3.557861   \n",
      "2      1.707841     3.015243  4.726314   0.997318    -2.367430   2.566758   \n",
      "3      1.476706     3.656363  4.202960   3.061100     2.787053   3.039318   \n",
      "4      1.448471     2.800828  2.065765   1.000557    -2.913132   2.936507   \n",
      "..          ...          ...       ...        ...          ...        ...   \n",
      "4      1.277331     7.326777  7.268292   6.089639     1.882286   4.314887   \n",
      "5      2.252109     4.214064  1.537967   1.080153    -3.063933   3.064757   \n",
      "6      2.204853     6.081378  4.116895   3.202558     0.234342   4.477169   \n",
      "7      1.978596     3.552581  2.698822   1.565245     2.473256   2.823749   \n",
      "8      2.644565     6.077863  4.019114   7.878779     3.137186   4.543500   \n",
      "\n",
      "                                              process  label  \n",
      "0   GluGluToHHTo2G2Qlnu_node_cHHH1_TuneCP5_14TeV-p...      0  \n",
      "1   GluGluToHHTo2G2Qlnu_node_cHHH1_TuneCP5_14TeV-p...      0  \n",
      "2   GluGluToHHTo2G2Qlnu_node_cHHH1_TuneCP5_14TeV-p...      0  \n",
      "3   GluGluToHHTo2G2Qlnu_node_cHHH1_TuneCP5_14TeV-p...      0  \n",
      "4   GluGluToHHTo2G2Qlnu_node_cHHH1_TuneCP5_14TeV-p...      0  \n",
      "..                                                ...    ...  \n",
      "4   GJet_Pt-20to40_DoubleEMEnriched_MGG-80toInf_Tu...      0  \n",
      "5   GJet_Pt-20to40_DoubleEMEnriched_MGG-80toInf_Tu...      0  \n",
      "6   GJet_Pt-20to40_DoubleEMEnriched_MGG-80toInf_Tu...      0  \n",
      "7   GJet_Pt-20to40_DoubleEMEnriched_MGG-80toInf_Tu...      0  \n",
      "8   GJet_Pt-20to40_DoubleEMEnriched_MGG-80toInf_Tu...      0  \n",
      "\n",
      "[369199 rows x 43 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84b51884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce physical event weight #\n",
    "# df['event_weight'] = pd.Series(np.zeros(df.shape[0]))\n",
    "# lumi = config['configuration']['luminosity']['HL-LHC']\n",
    "# for process in pd.unique(df['process']):\n",
    "#     print (f'Looking at process {process}')\n",
    "#     if 'cross-section' in config['files'][process].keys() and config['files'][process]['type'] != 'signal':\n",
    "#         cross_section = config[\"files\"][process][\"cross-section\"]\n",
    "#     else:\n",
    "#         cross_section = 1.\n",
    "#         # For signal, we assume unit cross section (otherwise significance can be too unstable)\n",
    "#     if 'branching-ratio' in config['files'][process].keys():\n",
    "#         BR = config[\"files\"][process][\"branching-ratio\"]\n",
    "#     else:\n",
    "#         BR = 1\n",
    "#     if 'generated-events' in config['files'][process].keys():\n",
    "        \n",
    "#         generated_events = config[\"files\"][process][\"generated-events\"]\n",
    "#     else:\n",
    "#         raise RuntimeError('Process {process} is missing `generated-events` entry, should not happen')\n",
    "        \n",
    "#     print (f'... cross-section = {cross_section}')\n",
    "#     print (f'... branching-ratio = {BR}')\n",
    "#     print (f'... generated-events = {generated_events}')\n",
    "#     factor = lumi * cross_section * BR / generated_events\n",
    "#     # We don't really care about luminosity because the scale of the weights do not matter, and you have a single lumi\n",
    "#     print (f'   -> Total factor = {factor}')\n",
    "#     # Apply to the new event_weight columns #\n",
    "#     df.loc[df[\"process\"]==process,'event_weight'] = df[df[\"process\"]==process]['weight'] * factor\n",
    "#     print (f'   Sum of weights = {df[df[\"process\"]==process][\"weight\"].sum()} -> {df[df[\"process\"]==process][\"event_weight\"].sum()}')\n",
    "\n",
    "df['event_weight'] = df['weight'].copy()\n",
    "\n",
    "if (df['event_weight'] < 0).sum() > 0:\n",
    "    raise RuntimeError(f\"There are {(df['event_weight'] < 0).sum()} events with negative event weight, this should not happen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09c50d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute training weight #\n",
    "if 'training_weight' in df.columns:\n",
    "    del df['training_weight']\n",
    "df['training_weight'] = df['event_weight'].copy()\n",
    "\n",
    "df.loc[df['label']==1,'training_weight'] *= df.shape[0]/2 / (df[df['label']==1]['event_weight']).sum()\n",
    "df.loc[df['label']==0,'training_weight'] *= df.shape[0]/2 / (df[df['label']==0]['event_weight']).sum()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9572a03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using event weight\n",
      "On average, per batch the total learning weight is\n",
      "\t... signal     :  3321.653049316 [91.33 events]\n",
      "\t... background :   351.920984039 [164.67 events]\n",
      "Using training weight\n",
      "On average, per batch the total learning weight is\n",
      "\t... signal     :   128.876377869 [92.97 events]\n",
      "\t... background :   132.757675400 [163.03 events]\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "importlib.reload(utils) # Reload in case file has changed\n",
    "print ('Using event weight')\n",
    "utils.checkBatches(df,weight_column='event_weight',batch_size=parameters['batch_size'])\n",
    "print ('Using training weight')\n",
    "utils.checkBatches(df,weight_column='training_weight',batch_size=parameters['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b92d8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the background and signal weights #\n",
    "fig,axs = plt.subplots(figsize=(16,8),nrows=2,ncols=3)\n",
    "fig.subplots_adjust(left=0.1, right=0.9, top=0.98, bottom=0.1, wspace=0.2,hspace=0.3)\n",
    "for irow,label in enumerate([0,1]):\n",
    "    for icol,column in enumerate(['weight','event_weight','training_weight']):\n",
    "        axs[irow,icol].hist(df[df['label']==label][column],bins=100,color='b')\n",
    "        axs[irow,icol].set_title(f\"Label = {label}\")\n",
    "        axs[irow,icol].set_xlabel(column)\n",
    "        axs[irow,icol].set_yscale('log')\n",
    "fig.savefig(\"event_weights_A.pdf\", dpi = 300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcfc5234",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the weights per process #\n",
    "if False:\n",
    "    with PdfPages(\"event_weights_B.pdf\") as pdf:\n",
    "        for process in pd.unique(df['process']):\n",
    "            fig,axs = plt.subplots(figsize=(16,6),nrows=1,ncols=3)\n",
    "            fig.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1, wspace=0.2,hspace=0.3)\n",
    "            fig.suptitle(f\"Process {process}\")\n",
    "            for icol,column in enumerate(['weight','event_weight','training_weight']):\n",
    "                axs[icol].hist(df[df['process']==process][column],bins=100,color='b')\n",
    "                axs[icol].set_xlabel(column)\n",
    "                axs[icol].set_xlim(0,(df[df['process']==process][column]).max()*1.5)\n",
    "                axs[icol].set_yscale('log')\n",
    "            pdf.savefig()\n",
    "            plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb4f4837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Eta_ph1   Phi_ph1  pT_mGG_ph1   Eta_ph2   Phi_ph2  pT_mGG_ph2  \\\n",
      "0   1.550125 -0.429081    1.146218 -0.046672  0.040071    0.259975   \n",
      "1  -0.331597 -0.570010    1.414617  0.195925  0.322665    0.686229   \n",
      "2  -0.010950 -2.823565    0.760772 -1.469144 -2.621348    0.511143   \n",
      "3   1.161311  1.227916    0.606318 -0.432271 -0.724228    0.281025   \n",
      "4   0.151180  2.670311    1.722849 -0.022241 -2.667792    0.675868   \n",
      "..       ...       ...         ...       ...       ...         ...   \n",
      "4  -2.392717 -0.644548    0.341475 -0.479692  2.095490    0.334221   \n",
      "5  -2.027300  0.506560    0.344458  0.342403 -0.463093    0.300636   \n",
      "6   1.474123 -0.947501    0.217085 -1.841440  2.814480    0.157748   \n",
      "7  -0.314875  3.136145    0.740329 -1.333250  0.654747    0.286807   \n",
      "8   0.828541 -2.872322    0.371863 -1.893330 -1.752634    0.186714   \n",
      "\n",
      "    deltaPhi_DiPh  deltaR_DiPh  nJets       E_jet1  ...      w2_mass  \\\n",
      "0        0.469152     1.664291      4   254.736557  ...   151.722565   \n",
      "1        0.892675     1.036893      4   189.149658  ...    60.545689   \n",
      "2        0.202216     1.472148      4   277.531464  ...    43.304264   \n",
      "3       -1.952143     2.519993      5   168.528030  ...   199.197479   \n",
      "4        0.945082     0.960862      4   193.526489  ...    51.208523   \n",
      "..            ...          ...    ...          ...  ...          ...   \n",
      "4        2.740039     3.341778      4  2556.459473  ...   760.344360   \n",
      "5       -0.969653     2.560414      4   118.241371  ...    42.823494   \n",
      "6       -2.521204     4.165264      4    67.549080  ...   179.879608   \n",
      "7       -2.481398     2.682243      4    39.805561  ...    52.833485   \n",
      "8        1.119688     2.943176      4    71.030098  ...  1707.189453   \n",
      "\n",
      "         ww_pT    ww_eta      ww_mass  mindeltaRPJ  maxdeltaRPJ  deltaRJJ  \\\n",
      "0   127.365433  3.194896   672.958923     2.284928     3.012725  3.968900   \n",
      "1   245.163589  1.641236   946.791199     0.983860     4.065130  3.455338   \n",
      "2    84.843834  0.229979   589.149414     1.707841     3.015243  4.726314   \n",
      "3    93.636475  2.304729   854.003601     1.476706     3.656363  4.202960   \n",
      "4   213.054977 -0.257412   387.911835     1.448471     2.800828  2.065765   \n",
      "..         ...       ...          ...          ...          ...       ...   \n",
      "4    23.746029  0.482731  5248.701660     1.277331     7.326777  7.268292   \n",
      "5    89.396782 -1.544019   558.982239     2.252109     4.214064  1.537967   \n",
      "6    33.233387 -4.747016  2028.770142     2.204853     6.081378  4.116895   \n",
      "7   110.354675  0.243046   373.384308     1.978596     3.552581  2.698822   \n",
      "8    83.755463 -3.803882  2178.556885     2.644565     6.077863  4.019114   \n",
      "\n",
      "    deltaRJJ2  deltaPhi_HH  deltaR_HH  \n",
      "0    3.113642    -3.040094   3.542051  \n",
      "1    2.105960    -3.057976   3.557861  \n",
      "2    0.997318    -2.367430   2.566758  \n",
      "3    3.061100     2.787053   3.039318  \n",
      "4    1.000557    -2.913132   2.936507  \n",
      "..        ...          ...        ...  \n",
      "4    6.089639     1.882286   4.314887  \n",
      "5    1.080153    -3.063933   3.064757  \n",
      "6    3.202558     0.234342   4.477169  \n",
      "7    1.565245     2.473256   2.823749  \n",
      "8    7.878779     3.137186   4.543500  \n",
      "\n",
      "[369199 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df[input_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a4ddd89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Even set has     184585 events [50.00%]\n",
      "Odd  set has     184614 events [50.00%]\n"
     ]
    }
   ],
   "source": [
    "# Determine splitting variable #\n",
    "split_var = df['Phi_ph1'].copy()\n",
    "split_var *= 1e4\n",
    "split_var -= np.floor(split_var) \n",
    "split_var = (split_var*1e1).astype(int)\n",
    "split_var = split_var %2 == 0\n",
    "print (f'Even set has {df[split_var].shape[0]:10d} events [{df[split_var].shape[0]/df.shape[0]*100:5.2f}%]')\n",
    "print (f'Odd  set has {df[~split_var].shape[0]:10d} events [{df[~split_var].shape[0]/df.shape[0]*100:5.2f}%]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6cd045db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using split type even\n",
      " 5.00% right quantile is when weight is at 1.3841331005096436\n",
      "  -> These events will be repeated and their learning weights reduced accordingly to avoid unstability\n",
      "Changes per process in training set\n",
      "GluGluToHHTo2B2G_node_cHHH1_TuneCP5_14TeV-powheg-pythia8_200PU.root\n",
      "...  66493 events [sum weight =   92184.906250] ->  66504 events [sum weight =   92184.906250]\n",
      "DiPhotonJetsBox_MGG-80toInf_14TeV-Sherpa_200PU.root\n",
      "...  53671 events [sum weight =   72799.812500] ->  56827 events [sum weight =   72799.796875]\n",
      "GJet_Pt-40toInf_DoubleEMEnriched_MGG-80toInf_TuneCUEP8M2T4_14TeV_Pythia8_200PU.root\n",
      "...    344 events [sum weight =   17850.439453] ->  12728 events [sum weight =   17850.439453]\n",
      "DiPhotonJetsBox_MGG-40to80_14TeV-Sherpa_200PU.root\n",
      "...    495 events [sum weight =    1262.663086] ->    533 events [sum weight =    1262.663086]\n",
      "GJet_Pt-20to40_DoubleEMEnriched_MGG-80toInf_TuneCP5_14TeV-pythia8_200PU.root\n",
      "...      5 events [sum weight =      94.905312] ->     65 events [sum weight =      94.905319]\n",
      "\n",
      "Total entries :         184614 ->         200263\n",
      "Total event sum :  184193.125000 ->  184193.109375\n",
      "\n",
      "Final sets\n",
      "Training set   = 140184\n",
      "Validation set = 60079\n",
      "Testing set    = 184585\n",
      "Total set      = 369199\n"
     ]
    }
   ],
   "source": [
    "# Sets splitting #\n",
    "print (f'Using split type {split}')\n",
    "# split_var = True (even number) | False (odd number)\n",
    "# Name of the model is related to the even | odd quality of the events during inference (ie, in bamboo)\n",
    "if split == 'even':\n",
    "    train_df = df[~split_var] # Trained on odd\n",
    "    test_df  = df[split_var]  # Evaluated on even \n",
    "elif split == 'odd':\n",
    "    train_df = df[split_var]  # Trained on even\n",
    "    test_df  = df[~split_var] # Evaluated on odd \n",
    "else:\n",
    "    raise RuntimeError(f'Split needs to be either odd or even, is {split}')\n",
    "\n",
    "# Randomize for training (always good to randomize) #\n",
    "train_df = train_df.sample(frac=1)\n",
    "\n",
    "# Quantile corrections #\n",
    "# When an event has a large weight, it can imbalance a lot the training, still the weight might have a meaning\n",
    "# Idea : instead of 1 event with wi>>1, we use N copies of the event with wf = wi/N\n",
    "# From the point of view of the physics it does not matter, the total event weight sum of each process is the same\n",
    "# From the point of view of the DNN, we have split a tough nut to crack into several smaller ones\n",
    "\n",
    "quantile_lim = train_df['training_weight'].quantile(quantile)\n",
    "print (f'{(1-quantile)*100:5.2f}% right quantile is when weight is at {quantile_lim}')\n",
    "print ('  -> These events will be repeated and their learning weights reduced accordingly to avoid unstability') \n",
    "\n",
    "# Select the events #\n",
    "idx_to_repeat = train_df['training_weight'] >= quantile_lim                          \n",
    "events_excess = train_df[idx_to_repeat].copy()\n",
    "\n",
    "saved_columns = train_df[['training_weight','process']].copy()\n",
    "\n",
    "# Compute multiplicative factor #\n",
    "factor = (events_excess['training_weight']/quantile_lim).values.astype(np.int32) \n",
    "\n",
    "# Correct the weights of events already in df #\n",
    "train_df.loc[idx_to_repeat,'training_weight'] /= factor\n",
    "\n",
    "# Add N-1 copies #\n",
    "arr_to_repeat = train_df[idx_to_repeat].values                                       \n",
    "repetition = np.repeat(np.arange(arr_to_repeat.shape[0]), factor-1)                   \n",
    "df_repeated = pd.DataFrame(np.take(arr_to_repeat,repetition,axis=0),columns=train_df.columns)\n",
    "df_repeated = df_repeated.astype(train_df.dtypes.to_dict()) # otherwise dtypes are object\n",
    "train_df = pd.concat((train_df,df_repeated),axis=0,ignore_index=True).sample(frac=1).reset_index() # Add and randomize\n",
    "\n",
    "# Printout #\n",
    "print ('Changes per process in training set')\n",
    "for process in pd.unique(train_df['process']):\n",
    "    N_before = saved_columns[saved_columns['process']==process].shape[0]\n",
    "    N_after  = train_df[train_df['process']==process].shape[0]\n",
    "    if N_before != N_after:\n",
    "        print (f\"{process:20s}\")\n",
    "        print (f\"... {N_before:6d} events [sum weight = {saved_columns[saved_columns['process']==process]['training_weight'].sum():14.6f}]\",end=' -> ')\n",
    "        print (f\"{N_after:6d} events [sum weight = {train_df[train_df['process']==process]['training_weight'].sum():14.6f}]\")\n",
    "    \n",
    "print ()\n",
    "print (f\"Total entries : {saved_columns.shape[0]:14d} -> {train_df.shape[0]:14d}\")\n",
    "print (f\"Total event sum : {saved_columns['training_weight'].sum():14.6f} -> {train_df['training_weight'].sum():14.6f}\")\n",
    "\n",
    "# Validation split #\n",
    "train_df,val_df  = train_test_split(train_df,test_size=0.3)\n",
    "\n",
    "# Printout #\n",
    "print ('\\nFinal sets')\n",
    "print (f'Training set   = {train_df.shape[0]}')\n",
    "print (f'Validation set = {val_df.shape[0]}')\n",
    "print (f'Testing set    = {test_df.shape[0]}')\n",
    "print (f'Total set      = {df.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01b20e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the background and signal weights #\n",
    "fig,axs = plt.subplots(figsize=(16,8),nrows=1,ncols=2)\n",
    "fig.subplots_adjust(left=0.1, right=0.9, top=0.98, bottom=0.1, wspace=0.2,hspace=0.3)\n",
    "\n",
    "if split == 'even':\n",
    "    axs[0].hist(df[~split_var]['training_weight'],bins=100,color='b')\n",
    "elif split == 'odd':\n",
    "    axs[0].hist(df[split_var]['training_weight'],bins=100,color='b')\n",
    "axs[0].set_title(\"Before correction\")\n",
    "axs[0].set_xlabel(\"Training weight\")\n",
    "axs[0].set_yscale('log')\n",
    "axs[1].hist(train_df['training_weight'],bins=100,color='b')\n",
    "axs[1].set_title(\"After correction\")\n",
    "axs[1].set_xlabel(\"Training weight\")\n",
    "axs[1].set_yscale('log')\n",
    "fig.savefig(\"event_weights_C.pdf\", dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a3c62ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 22:00:26.296164: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cvmfs/sft.cern.ch/lcg/releases/MCGenerators/thepeg/2.2.1-8d929/x86_64-centos7-gcc10-opt/lib/ThePEG:/cvmfs/sft.cern.ch/lcg/releases/MCGenerators/herwig++/7.2.1-f3599/x86_64-centos7-gcc10-opt/lib/Herwig:/cvmfs/sft.cern.ch/lcg/views/LCG_101/x86_64-centos7-gcc10-opt/lib/python3.9/site-packages/torch/lib:/cvmfs/sft.cern.ch/lcg/views/LCG_101/x86_64-centos7-gcc10-opt/lib/python3.9/site-packages/tensorflow:/cvmfs/sft.cern.ch/lcg/views/LCG_101/x86_64-centos7-gcc10-opt/lib/python3.9/site-packages/tensorflow/contrib/tensor_forest:/cvmfs/sft.cern.ch/lcg/views/LCG_101/x86_64-centos7-gcc10-opt/lib/python3.9/site-packages/tensorflow/python/framework:/cvmfs/sft.cern.ch/lcg/releases/java/8u222-884d8/x86_64-centos7-gcc10-opt/jre/lib/amd64:/cvmfs/sft.cern.ch/lcg/views/LCG_101/x86_64-centos7-gcc10-opt/lib64:/cvmfs/sft.cern.ch/lcg/views/LCG_101/x86_64-centos7-gcc10-opt/lib:/cvmfs/sft.cern.ch/lcg/releases/gcc/10.3.0-f5826/x86_64-centos7/lib:/cvmfs/sft.cern.ch/lcg/releases/gcc/10.3.0-f5826/x86_64-centos7/lib64:/cvmfs/sft.cern.ch/lcg/releases/binutils/2.36.1-a9696/x86_64-centos7/lib:/cvmfs/grid.cern.ch/centos7-umd4-ui-4.0.3-1_191004/lib64:/cvmfs/grid.cern.ch/centos7-umd4-ui-4.0.3-1_191004/lib:/cvmfs/grid.cern.ch/centos7-umd4-ui-4.0.3-1_191004/usr/lib64:/cvmfs/grid.cern.ch/centos7-umd4-ui-4.0.3-1_191004/usr/lib:/cvmfs/sft.cern.ch/lcg/releases/R/3.6.3-dfb24/x86_64-centos7-gcc10-opt/lib64/R/library/readr/rcon\n",
      "2022-02-04 22:00:26.296228: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-02-04 22:00:26.296295: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ingrid-ui1.cism.ucl.ac.be): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "# Input layer #\n",
    "inputs = keras.Input(shape=(len(input_vars),), name=\"particles\")\n",
    "\n",
    "# Preprocessing layer\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "normalizer = preprocessing.Normalization(mean     = train_df[input_vars].mean(axis=0),\n",
    "                                         variance = train_df[input_vars].var(axis=0),\n",
    "                                         name     = 'Normalization')(inputs)\n",
    "    # this layer does the preprocessing (x-mu)/std for each input\n",
    "# Dense (hidden) layers #\n",
    "x = normalizer\n",
    "for i in range(parameters['n_layers']):\n",
    "    x = layers.Dense(units                = parameters['n_neurons'], \n",
    "                     activation           = parameters['hidden_activation'], \n",
    "                     activity_regularizer = tf.keras.regularizers.l2(parameters['l2']),\n",
    "                     name                 = f\"dense_{i}\")(x)\n",
    "    if parameters['batch_norm']:\n",
    "        x = layers.BatchNormalization()(x)\n",
    "    if parameters['dropout'] > 0.:\n",
    "        x = layers.Dropout(parameters['dropout'])(x)\n",
    "# Output layer #\n",
    "outputs = layers.Dense(units                = 1, \n",
    "                       activation           = parameters['output_activation'],\n",
    "                       activity_regularizer = tf.keras.regularizers.l2(parameters['l2']),\n",
    "                       name                 = \"predictions\")(x)\n",
    "\n",
    "# Registering the model #\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4251ca78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 22:00:26.741478: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-02-04 22:00:26.742329: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2394070000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input (after normalization) mean (should be close to 0)\n",
      "[-5.0810045e-09  6.4360806e-09  1.3702767e-08 -1.0965403e-08\n",
      " -1.0913742e-08 -6.2938549e-10 -5.6146159e-09 -2.4622207e-07\n",
      " -4.7984071e-07 -5.4651196e-08  1.8131362e-07 -1.4463642e-08\n",
      " -4.3768917e-09  5.2276519e-08 -7.5531787e-08  3.8521026e-09\n",
      " -1.5522787e-08 -9.3868895e-09 -4.7825644e-08  2.5234947e-08\n",
      " -9.7324886e-09 -5.3745545e-08  1.7810217e-07  6.4726469e-09\n",
      "  1.5052528e-08 -7.6477832e-08 -2.6707161e-08 -2.2552006e-08\n",
      " -9.5128307e-08  4.4002775e-09 -2.9267859e-09  6.6034985e-08\n",
      "  1.3554376e-08 -1.0443909e-08  1.2364995e-07 -5.6874075e-07\n",
      "  7.6988059e-08  6.7754662e-08 -2.0405654e-08  1.5532237e-07]\n",
      "Input (after normalization) variance (should be close to 1)\n",
      "[0.9999691  0.9999759  0.9999622  0.9999462  0.9999594  0.9999691\n",
      " 0.9999876  0.99997514 0.9993883  0.99997044 0.99995774 0.9999627\n",
      " 0.99996823 0.99996567 0.9999658  0.9999649  0.9999766  0.99996436\n",
      " 0.9999689  0.9999704  0.99997294 0.9999777  0.99997    0.9999678\n",
      " 0.99996746 0.99997514 0.9999709  0.99996346 0.9999599  0.99996454\n",
      " 0.99996364 0.99996823 0.9999758  0.99997556 0.9999691  0.9999832\n",
      " 0.9999554  0.9999707  0.99997824 0.99996436]\n"
     ]
    }
   ],
   "source": [
    "model_preprocess = keras.Model(inputs=inputs, outputs=normalizer)\n",
    "out_test = model_preprocess.predict(train_df[input_vars],batch_size=5000)\n",
    "print ('Input (after normalization) mean (should be close to 0)')\n",
    "print (out_test.mean(axis=0))\n",
    "print ('Input (after normalization) variance (should be close to 1)')\n",
    "print (out_test.var(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40426231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "particles (InputLayer)       [(None, 40)]              0         \n",
      "_________________________________________________________________\n",
      "Normalization (Normalization (None, 40)                81        \n",
      "_________________________________________________________________\n",
      "dense_0 (Dense)              (None, 64)                2624      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 11,858\n",
      "Trainable params: 11,393\n",
      "Non-trainable params: 465\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/sft.cern.ch/lcg/views/LCG_101/x86_64-centos7-gcc10-opt/lib/python3.9/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    #optimizer=keras.optimizers.RMSprop(),\n",
    "    optimizer=keras.optimizers.Adam(lr=parameters['lr']),  # Optimizer\n",
    "    # Loss function to minimize\n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    # List of metrics to monitor\n",
    "    metrics=[keras.metrics.BinaryAccuracy(),\n",
    "             tf.keras.metrics.AUC(),\n",
    "             tf.keras.metrics.Precision(),\n",
    "             tf.keras.metrics.Recall()],\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ea4a060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks #\n",
    "early_stopping = EarlyStopping(monitor = 'val_loss',\n",
    "                               min_delta = 0.001, \n",
    "                               patience = 20,\n",
    "                               verbose=1,\n",
    "                               mode='min',\n",
    "                               restore_best_weights=True)\n",
    "# Stop the learning when val_loss stops increasing \n",
    "# https://keras.io/api/callbacks/early_stopping/\n",
    "\n",
    "reduce_plateau = ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                                   factor = 0.1,\n",
    "                                   min_delta = 0.001, \n",
    "                                   patience = 8,\n",
    "                                   min_lr = 1e-8,\n",
    "                                   verbose=2,\n",
    "                                   mode='min')\n",
    "# reduce LR if not improvement for some time \n",
    "# https://keras.io/api/callbacks/reduce_lr_on_plateau/\n",
    "import History \n",
    "importlib.reload(History)\n",
    "loss_history = History.LossHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa63501",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "548/548 - 7s - loss: 0.4204 - binary_accuracy: 0.6184 - auc: 0.6947 - precision: 0.4551 - recall: 0.7644 - val_loss: 0.3930 - val_binary_accuracy: 0.6229 - val_auc: 0.7022 - val_precision: 0.4611 - val_recall: 0.7811\n",
      "Epoch 2/200\n",
      "548/548 - 3s - loss: 0.3808 - binary_accuracy: 0.6283 - auc: 0.7067 - precision: 0.4644 - recall: 0.7893 - val_loss: 0.3790 - val_binary_accuracy: 0.6312 - val_auc: 0.7056 - val_precision: 0.4680 - val_recall: 0.7805\n",
      "Epoch 3/200\n",
      "548/548 - 3s - loss: 0.3692 - binary_accuracy: 0.6313 - auc: 0.7112 - precision: 0.4673 - recall: 0.7983 - val_loss: 0.3726 - val_binary_accuracy: 0.6269 - val_auc: 0.7107 - val_precision: 0.4651 - val_recall: 0.7980\n",
      "Epoch 4/200\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_df[input_vars],\n",
    "    train_df['label'],\n",
    "    verbose=2,\n",
    "    batch_size=parameters['batch_size'],\n",
    "    epochs=parameters['epochs'],\n",
    "    sample_weight=train_df['training_weight'],\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    validation_data=(val_df[input_vars],val_df['label'],val_df['training_weight']),\n",
    "    callbacks = [early_stopping, reduce_plateau, loss_history],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94334845",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "History.PlotHistory(loss_history,params=parameters,outputName=f'loss_{suffix}_{split}.png')\n",
    "# Params is a dict of parameters with name and values\n",
    "# used for plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb255ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce output on the test set as new column #\n",
    "output = model.predict(test_df[input_vars],batch_size=5000)\n",
    "    # Here the batch_size arg is independent of the learning\n",
    "    # Default is 32, but it can become slow, by using large value it will just compute more values in parallel\n",
    "    # (more or less parallel, we are not using a GPU)\n",
    "if 'output' in test_df.columns:\n",
    "    # If already output, need to remove to add again\n",
    "    # avoid issues in case you run this cell multiple times\n",
    "    del test_df['output']\n",
    "test_df = pd.concat((test_df,pd.DataFrame(output,columns=['output'],index=test_df.index)),axis=1)\n",
    "# We add the output as a column, a bit messy, different ways, here I use a concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f10f696",
   "metadata": {},
   "outputs": [],
   "source": [
    "import roc\n",
    "importlib.reload(roc) # Reload in case file has changed\n",
    "roc.rocAndSig(y_true     = test_df['label'],\n",
    "              y_pred     = test_df['output'],\n",
    "              w_roc      = test_df['training_weight'],\n",
    "              w_sig      = test_df['event_weight'],\n",
    "              outputName = f'roc_{suffix}_{split}.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e8e583",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(figsize=(16,8),nrows=1,ncols=2)\n",
    "fig.subplots_adjust(left=0.1, right=0.9, top=0.98, bottom=0.1, wspace=0.2,hspace=0.3)\n",
    "\n",
    "sig_df = test_df[test_df['label']==1]\n",
    "bkg_df = test_df[test_df['label']==0]\n",
    "\n",
    "# Manual binning so we can compute significance #\n",
    "bins = np.linspace(0,1,51)\n",
    "centers = (bins[1:]+bins[:-1])/2\n",
    "widths = np.diff(bins)\n",
    "\n",
    "\n",
    "def get_bin_content(y,w):\n",
    "    digitized = np.digitize(y,bins)\n",
    "    return np.array([w[digitized==i].sum() for i in range(1, len(bins))])\n",
    "\n",
    "for icol,weight in enumerate(['event_weight','training_weight']):\n",
    "    # Fill the bins myself #\n",
    "    b = get_bin_content(bkg_df['output'],bkg_df[weight])\n",
    "    s = get_bin_content(sig_df['output'],sig_df[weight])\n",
    "    cumsum_s_left = np.cumsum(s)/s.sum()\n",
    "    cumsum_b_left = np.cumsum(b)/b.sum()\n",
    "    cumsum_s_right = np.cumsum(s[::-1])[::-1]/s.sum()\n",
    "    cumsum_b_right = np.cumsum(b[::-1])[::-1]/b.sum()\n",
    "    # Need to integrate all the bins right of the DNN cut to get significance\n",
    "    z_left = np.nan_to_num(np.sqrt(2*((cumsum_s_left+cumsum_b_left)*np.log(1+cumsum_s_left/cumsum_b_left)-cumsum_s_left)))\n",
    "    z_right = np.nan_to_num(np.sqrt(2*((cumsum_s_right+cumsum_b_right)*np.log(1+cumsum_s_right/cumsum_b_right)-cumsum_s_right)))\n",
    "    z_left /= z_left.max()\n",
    "    z_right /= z_right.max()\n",
    "    axs[icol].bar(x=centers,height=b,width=widths,alpha=0.5,color='b',label='Bkg')\n",
    "    axs[icol].bar(x=centers,height=s,width=widths,alpha=0.5,color='g',label=r'$HH \\rightarrow WW \\gamma \\gamma$')\n",
    "    ax2=axs[icol].twinx()   \n",
    "    ax2.plot(centers,z_left,color='r',label='Significance (left of cut) [normed]')\n",
    "    ax2.plot(centers,cumsum_s_left,color='g',label='Signal content (left of cut)')\n",
    "    ax2.plot(centers,cumsum_b_left,color='b',label='Bkg content (left of cut)')\n",
    "    ax2.plot(centers,z_right,color='r',linestyle='--',label='Significance (right of cut) [normed]')\n",
    "    ax2.plot(centers,cumsum_s_right,color='g',linestyle='--',label='Signal content (right of cut)')\n",
    "    ax2.plot(centers,cumsum_b_right,color='b',linestyle='--',label='Bkg content (right of cut)')\n",
    "    #ax2.set_yscale(\"log\")\n",
    "    #ax2.set_ylim([0,z.max()*1.1])\n",
    "    ax2.set_ylim([0,1.4])\n",
    "    ax2.set_ylabel('CDF')\n",
    "    ax2.legend(loc='upper right')\n",
    "\n",
    "    axs[icol].set_title(f\"Using {weight}\")\n",
    "    axs[icol].set_xlabel('DNN output')\n",
    "    axs[icol].set_ylabel('Yield')\n",
    "    axs[icol].set_ylim([s.min()*0.1,np.maximum(s,b).max()*100])\n",
    "    axs[icol].set_yscale('log')\n",
    "    axs[icol].legend(loc='upper left')\n",
    "fig.savefig(f\"prediction_{suffix}_{split}.pdf\", dpi = 300)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86da4315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(test_df[input_vars], \n",
    "                        test_df['label'], \n",
    "                        sample_weight = test_df['training_weight'], \n",
    "                        batch_size = 5000,\n",
    "                        verbose=2)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051f1247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model and architecture to single file\n",
    "modelName = f\"model_{suffix}_{split}\"\n",
    "model.save(modelName)\n",
    "print(f\"Saved model to disk as {modelName}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
